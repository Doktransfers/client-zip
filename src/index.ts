import "./polyfills.ts"
import { BufferLike, StreamLike, normalizeInput, ReadableFromIterator } from "./input.ts"
import { normalizeMetadata } from "./metadata.ts"
import { loadFiles, contentLength, ForAwaitable, ZipEntryMetadata } from "./zip.ts"

/** The file name, modification date and size will be read from the input;
 * extra arguments can be given to override the input’s metadata. */
type InputWithMeta = File | Response | { input: File | Response, name?: any, lastModified?: any, size?: number | bigint, mode?: number }

/** Intrinsic size, but the file name must be provided and modification date can’t be guessed. */
type InputWithSizeMeta = { input: BufferLike, name: any, lastModified?: any, size?: number | bigint, mode?: number }

/** The file name must be provided ; modification date and content length can’t be guessed. */
type InputWithoutMeta = { input: StreamLike, name: any, lastModified?: any, size?: number | bigint, mode?: number }

/** The folder name must be provided ; modification date can’t be guessed. */
type InputFolder = { name: any, lastModified?: any, input?: never, size?: never, mode?: number }

/** Both filename and size must be provided ; input is not helpful here. */
type JustMeta = { input?: StreamLike | undefined, name: any, lastModified?: any, size: number | bigint, mode?: number }

export type Options = {
  /** The size of the first part of the file. */
  firstPartSize?: number
  /** The size of the last part of the file. */
  lastPartSize?: number
  /** If provided, the returned Response will have its `Content-Length` header set to this value.
   * It can be computed accurately with the `predictLength` function. */
  length?: number | bigint
  /** If provided, the returned Response will have its `Content-Length` header set to the result of
   * calling `predictLength` on that metadata. Overrides the `length` option. */
  metadata?: Iterable<InputWithMeta | InputWithSizeMeta | JustMeta>
  /** The ZIP *language encoding flag* will always be set when a filename was given as a string,
   * but when it is given as an ArrayView or ArrayBuffer, it depends on this option :
   * - `true`: always on (ArrayBuffers will *always* be flagged as UTF-8) — recommended,
   * - `false`: always off (ArrayBuffers will *never* be flagged as UTF-8),
   * - `undefined`: each ArrayBuffer will be tested and flagged if it is valid UTF-8. */
  buffersAreUTF8?: boolean
  /** Callback that receives metadata for each ZIP entry as it's processed.
   * Useful for getting entry offsets, data offsets, CRC32 values, etc. */
  onEntry?: (entry: ZipEntryMetadata) => void
  /** AbortSignal to cancel the ZIP generation process.
   * When aborted, the ZIP generation will stop and throw an AbortError. */
  signal?: AbortSignal
}

function normalizeArgs(file: InputWithMeta | InputWithSizeMeta | InputWithoutMeta | InputFolder | JustMeta) {
  return file instanceof File || file instanceof Response
    ? [[file], [file]] as const
    : [[file.input, file.name, file.size], [file.input, file.lastModified, file.mode]] as const
}

function* mapMeta(files: Iterable<InputWithMeta | InputWithSizeMeta | JustMeta | InputFolder>) {
  // @ts-ignore type inference isn't good enough for this… yet…
  // but rewriting the code to be more explicit would make it longer
  for (const file of files) yield normalizeMetadata(...normalizeArgs(file)[0])
}

function mapFiles(files: ForAwaitable<InputWithMeta | InputWithSizeMeta | InputWithoutMeta | InputFolder>) {
  // @ts-ignore TypeScript really needs to catch up
  const iterator = files[Symbol.iterator in files ? Symbol.iterator : Symbol.asyncIterator]()
  return {
    async next() {
      const res = await iterator.next()
      if (res.done) return res
      const [metaArgs, dataArgs] = normalizeArgs(res.value)
      // @ts-ignore type inference isn't good enough for this… yet…
      // but rewriting the code to be more explicit would make it longer
      return { done: false, value: Object.assign(normalizeInput(...dataArgs), normalizeMetadata(...metaArgs)) }
    },
    throw: iterator.throw?.bind(iterator),
    [Symbol.asyncIterator]() { return this }
  }
}

/** Given an iterable of file metadata (or equivalent),
 * @returns the exact byte length of the Zip file that would be generated by `downloadZip`. */
export const predictLength = (files: Iterable<InputWithMeta | InputWithSizeMeta | JustMeta | InputFolder>) => contentLength(mapMeta(files))

// Export the ZipEntryMetadata interface for use by consumers
export type { ZipEntryMetadata }

// Enhanced ReadableStream interface with size property
export interface ReadableStreamWithSize<T> extends ReadableStream<T> {
  readonly size?: number
}

export function downloadZip(files: ForAwaitable<InputWithMeta | InputWithSizeMeta | InputWithoutMeta | InputFolder>, options: Options = {}) {
  const headers: Record<string, any> = { "Content-Type": "application/zip", "Content-Disposition": "attachment" }
  if ((typeof options.length === "bigint" || Number.isInteger(options.length)) && options.length! > 0) headers["Content-Length"] = String(options.length)
  if (options.metadata) headers["Content-Length"] = String(predictLength(options.metadata))
  return new Response(makeZip(files, options), { headers })
}

export function downloadZipWithEntries(files: ForAwaitable<InputWithMeta | InputWithSizeMeta | InputWithoutMeta | InputFolder>, options: Options = {}): { response: Response, entries: Promise<ZipEntryMetadata[]> } {
  const { stream, entries } = makeZipWithEntries(files, options)

  const headers: Record<string, any> = { "Content-Type": "application/zip", "Content-Disposition": "attachment" }
  if ((typeof options.length === "bigint" || Number.isInteger(options.length)) && options.length! > 0) headers["Content-Length"] = String(options.length)
  if (options.metadata) headers["Content-Length"] = String(predictLength(options.metadata))

  const response = new Response(stream, { headers })

  return {
    response,
    entries
  }
}

export function makeZip(files: ForAwaitable<InputWithMeta | InputWithSizeMeta | InputWithoutMeta | InputFolder>, options: Options = {}): ReadableStreamWithSize<Uint8Array> {
  const mapped = mapFiles(files)

  // Calculate the predicted size if possible
  let predictedSize: bigint | undefined
  try {
    // Try to predict size using the metadata approach
    if (options.metadata) {
      predictedSize = predictLength(options.metadata)
    } else {
      // Try to convert files to metadata for prediction
      const filesArray = Array.isArray(files) ? files : []
      if (filesArray.length > 0) {
        const metaIterable = mapMeta(filesArray)
        predictedSize = contentLength(metaIterable)
      }
    }
  } catch {
    // If prediction fails, size will be undefined
  }

  const stream = ReadableFromIterator(loadFiles(mapped, options), mapped, options.signal, predictedSize ? Number(predictedSize) : undefined);

  // Create enhanced stream with size property
  const enhancedStream = stream as ReadableStreamWithSize<Uint8Array>
  if (predictedSize !== undefined) {
    Object.defineProperty(enhancedStream, 'size', {
      value: Number(predictedSize),
      writable: false,
      enumerable: true,
      configurable: false
    })
  }

  return enhancedStream
}

export function makeZipWithEntries(files: ForAwaitable<InputWithMeta | InputWithSizeMeta | InputWithoutMeta | InputFolder>, options: Options = {}): { stream: ReadableStreamWithSize<Uint8Array>, entries: Promise<ZipEntryMetadata[]> } {
  const mapped = mapFiles(files)
  const entriesCollector: ZipEntryMetadata[] = []

  let entriesResolve!: (entries: ZipEntryMetadata[]) => void
  let entriesReject!: (error: any) => void

  const entriesPromise = new Promise<ZipEntryMetadata[]>((resolve, reject) => {
    entriesResolve = resolve
    entriesReject = reject
  })

  // Create options with our entry collector
  const optionsWithCollector = {
    ...options,
    onEntry: (entry: ZipEntryMetadata) => {
      entriesCollector.push(entry)
      // Also call the original callback if provided
      options.onEntry?.(entry)
    }
  }

  // Calculate the predicted size if possible (same logic as makeZip)
  let predictedSize: bigint | undefined
  try {
    if (options.metadata) {
      predictedSize = predictLength(options.metadata)
    } else {
      const filesArray = Array.isArray(files) ? files : []
      if (filesArray.length > 0) {
        const metaIterable = mapMeta(filesArray)
        predictedSize = contentLength(metaIterable)
      }
    }
  } catch {
    // If prediction fails, size will be undefined
  }

  // Create the stream with a wrapper that resolves the entries promise when done
  const originalIterator = loadFiles(mapped, optionsWithCollector)
  const wrappedIterator = wrapIteratorForEntries(originalIterator, entriesResolve, entriesReject, entriesCollector)

  const stream = ReadableFromIterator(wrappedIterator, mapped, options.signal, predictedSize ? Number(predictedSize) : undefined)

  // Create enhanced stream with size property
  const enhancedStream = stream as ReadableStreamWithSize<Uint8Array>
  if (predictedSize !== undefined) {
    Object.defineProperty(enhancedStream, 'size', {
      value: Number(predictedSize),
      writable: false,
      enumerable: true,
      configurable: false
    })
  }

  return {
    stream: enhancedStream,
    entries: entriesPromise
  }
}

/**
 * Create a ZIP archive as an async iterator instead of a ReadableStream
 * This is more compatible with iOS devices that have issues with ReadableStream
 * @param files The files to include in the ZIP
 * @param options ZIP creation options
 * @returns An async iterator that yields Uint8Array chunks and a promise for entries metadata
 */
export function makeZipIterator(files: ForAwaitable<InputWithMeta | InputWithSizeMeta | InputWithoutMeta | InputFolder>, options: Options = {}): { iterator: AsyncIterator<Uint8Array>, entries: Promise<ZipEntryMetadata[]>, size?: number } {
  const mapped = mapFiles(files)
  const entriesCollector: ZipEntryMetadata[] = []

  let entriesResolve!: (entries: ZipEntryMetadata[]) => void
  let entriesReject!: (error: any) => void

  const entriesPromise = new Promise<ZipEntryMetadata[]>((resolve, reject) => {
    entriesResolve = resolve
    entriesReject = reject
  })

  // Create options with our entry collector
  const optionsWithCollector = {
    ...options,
    onEntry: (entry: ZipEntryMetadata) => {
      entriesCollector.push(entry);
      // Also call the original callback if provided
      options.onEntry?.(entry)
    }
  }

  // Calculate the predicted size if possible
  let predictedSize: bigint | undefined
  try {
    if (options.metadata) {
      predictedSize = predictLength(options.metadata)
    } else {
      const filesArray = Array.isArray(files) ? files : []
      if (filesArray.length > 0) {
        const metaIterable = mapMeta(filesArray)
        predictedSize = contentLength(metaIterable)
      }
    }
  } catch {
    // If prediction fails, size will be undefined
  }

  // Create the iterator with a wrapper that resolves the entries promise when done
  const originalIterator = loadFiles(mapped, optionsWithCollector)
  const wrappedIterator = wrapIteratorForEntries(originalIterator, entriesResolve, entriesReject, entriesCollector)

  return {
    iterator: wrappedIterator,
    entries: entriesPromise,
    size: predictedSize ? Number(predictedSize) : undefined
  }
}

async function* wrapIteratorForEntries<T>(
  iterator: AsyncGenerator<T>,
  resolve: (entries: ZipEntryMetadata[]) => void,
  reject: (error: any) => void,
  entriesCollector: ZipEntryMetadata[]
): AsyncGenerator<T> {
  try {
    let result = await iterator.next()
    while (!result.done) {
      yield result.value
      result = await iterator.next()
    }
    // Iterator completed successfully, resolve with collected entries
    resolve(entriesCollector)
    return result.value
  } catch (error) {
    // Iterator failed, reject the entries promise
    reject(error)
    throw error
  }
}